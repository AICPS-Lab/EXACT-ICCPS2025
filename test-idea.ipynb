{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S8 has 20 samples, 16 for train, 4 for test\n",
      "S17 has 19 samples, 15 for train, 4 for test\n",
      "S13 has 19 samples, 15 for train, 4 for test\n",
      "S12 has 20 samples, 16 for train, 4 for test\n",
      "S11 has 20 samples, 16 for train, 4 for test\n",
      "S20 has 15 samples, 12 for train, 3 for test\n",
      "S1 has 20 samples, 16 for train, 4 for test\n",
      "S15 has 20 samples, 16 for train, 4 for test\n",
      "S6 has 19 samples, 15 for train, 4 for test\n",
      "S5 has 20 samples, 16 for train, 4 for test\n",
      "S10 has 20 samples, 16 for train, 4 for test\n",
      "S2 has 19 samples, 15 for train, 4 for test\n",
      "S16 has 20 samples, 16 for train, 4 for test\n",
      "S18 has 20 samples, 16 for train, 4 for test\n",
      "S4 has 19 samples, 15 for train, 4 for test\n",
      "S14 has 20 samples, 16 for train, 4 for test\n",
      "S19 has 20 samples, 16 for train, 4 for test\n",
      "S3 has 10 samples, 8 for train, 2 for test\n",
      "S7 has 20 samples, 16 for train, 4 for test\n",
      "S9 has 20 samples, 16 for train, 4 for test\n"
     ]
    }
   ],
   "source": [
    "filename = './datasets/spar/spar_dataset'\n",
    "seed = 25\n",
    "# read through the folder that end with csv:\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "classes = []\n",
    "subjs = []\n",
    "for root, dirs, files in os.walk(filename):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\") and 'R' in file:\n",
    "            label = file.split('_')[1]\n",
    "            subj = file.split('_')[0]\n",
    "            if label not in classes:\n",
    "                classes.append(label)\n",
    "            if subj not in subjs:\n",
    "                subjs.append(subj)\n",
    "            # print(os.path.join(root, file))\n",
    "            # df = pd.read_csv(os.path.join(root, file))\n",
    "\n",
    "# generate train combo => ABC, ABD, ... # test combo => BCD (some combo that was not seem in train) based on the classes\n",
    "train_combo = [('E1', 'E2', 'E3')]\n",
    "test_combo = [('E3', 'E1', 'E2')]\n",
    "\n",
    "assert all([each in classes for comb in train_combo for each in comb]), 'train combo not in classes'\n",
    "assert all([each in classes for comb in test_combo for each in comb]), 'test combo not in classes'\n",
    "train_classes = list(set([each for comb in train_combo for each in comb]))\n",
    "le = LabelEncoder()\n",
    "le.fit(train_classes)\n",
    "random.seed(seed)\n",
    "train_samples = []\n",
    "test_samples = []\n",
    "for each_subj in subjs:\n",
    "    collection = {class_name: [] for class_name in classes}\n",
    "    for root, dirs, files in os.walk(filename):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") and 'R' in file and each_subj == file.split('_')[0]:\n",
    "                label = file.split('_')[1]\n",
    "                collection[label].append(file)\n",
    "\n",
    "    lengths = [len(collection[class_name]) for class_name in classes]\n",
    "    minimum = min(lengths)\n",
    "    # 80% for train, 20% for test\n",
    "    train_length = int(minimum * 0.8)\n",
    "    test_length = minimum - train_length\n",
    "    print(f'{each_subj} has {minimum} samples, {train_length} for train, {test_length} for test')\n",
    "    # generate train and test data\n",
    "    \n",
    "    # randomly extract one sample of label from the collection and remove that label from the list in the collection:\n",
    "    for _ in range(train_length):\n",
    "        for i in train_combo:\n",
    "            cur_combo = []\n",
    "            for j in i:\n",
    "                selected_sample = random.choice(collection[j])\n",
    "                collection[j].remove(selected_sample)\n",
    "                cur_combo.append(selected_sample)\n",
    "            train_samples.append(cur_combo)\n",
    "    for _ in range(test_length):\n",
    "        for i in test_combo:\n",
    "            cur_combo = []\n",
    "            for j in i:\n",
    "                selected_sample = random.choice(collection[j])\n",
    "                collection[j].remove(selected_sample)\n",
    "                cur_combo.append(selected_sample)\n",
    "            test_samples.append(cur_combo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 77)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112181, 6) (112181,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-1.100601,  0.461792, -0.851196,  0.119459, -0.400505, -0.099266],\n",
       "        [-1.160965,  0.400863, -0.83046 , -0.17802 ,  0.013153,  0.019373],\n",
       "        [-1.16362 ,  0.484878, -0.711365, -0.156335,  0.423481,  0.204342],\n",
       "        ...,\n",
       "        [ 0.368675,  0.7874  ,  0.718854,  0.976343,  1.023894,  0.792925],\n",
       "        [ 0.403206,  0.739999,  0.770553,  0.689447,  0.591772,  0.616874],\n",
       "        [ 0.413861,  0.733648,  0.782116,  0.261578,  0.189895,  0.465816]]),\n",
       " array([0, 0, 0, ..., 2, 2, 2]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def combo_to_np(combo, le: LabelEncoder):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for each_combo in combo:\n",
    "        for each_file in each_combo:\n",
    "            df = pd.read_csv(os.path.join(filename, each_file))\n",
    "            samples.append(df.to_numpy()[:, 1:7])\n",
    "            labels.append([le.transform([each_file.split('_')[1]])[0]] * df.shape[0])\n",
    "            # print('labels', labels)\n",
    "    # convert to np:\n",
    "    samples = np.concatenate(samples)\n",
    "    labels = np.concatenate(labels)\n",
    "    print(samples.shape, labels.shape)\n",
    "    return samples, labels\n",
    "combo_to_np(train_samples, le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S8 has 20 samples, 16 for train, 4 for test\n",
      "S17 has 19 samples, 15 for train, 4 for test\n",
      "S13 has 19 samples, 15 for train, 4 for test\n",
      "S12 has 20 samples, 16 for train, 4 for test\n",
      "S11 has 20 samples, 16 for train, 4 for test\n",
      "S20 has 15 samples, 12 for train, 3 for test\n",
      "S1 has 20 samples, 16 for train, 4 for test\n",
      "S15 has 20 samples, 16 for train, 4 for test\n",
      "S6 has 19 samples, 15 for train, 4 for test\n",
      "S5 has 20 samples, 16 for train, 4 for test\n",
      "S10 has 20 samples, 16 for train, 4 for test\n",
      "S2 has 19 samples, 15 for train, 4 for test\n",
      "S16 has 20 samples, 16 for train, 4 for test\n",
      "S18 has 20 samples, 16 for train, 4 for test\n",
      "S4 has 19 samples, 15 for train, 4 for test\n",
      "S14 has 20 samples, 16 for train, 4 for test\n",
      "S19 has 20 samples, 16 for train, 4 for test\n",
      "S3 has 10 samples, 8 for train, 2 for test\n",
      "S7 has 20 samples, 16 for train, 4 for test\n",
      "S9 has 20 samples, 16 for train, 4 for test\n",
      "(112103, 6) (112103,)\n",
      "(28519, 6) (28519,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([[-1.089524,  0.295365, -0.578415,  0.184561, -0.76863 , -0.247805],\n",
       "         [-1.099212,  0.35115 , -0.661316, -0.028319, -0.513699, -0.189888],\n",
       "         [-1.118485,  0.389222, -0.67424 , -0.188227, -0.220624, -0.148195],\n",
       "         ...,\n",
       "         [ 0.394497,  0.599451,  0.842365, -0.074083, -0.505722, -0.075523],\n",
       "         [ 0.391111,  0.615858,  0.847801, -0.223795, -0.689337, -0.187778],\n",
       "         [ 0.395309,  0.639557,  0.818864, -0.298615, -0.914531, -0.288899]]),\n",
       "  array([0, 0, 0, ..., 2, 2, 2])),\n",
       " (array([[ 0.065735,  1.028625,  0.254135, -0.238591,  0.203898, -0.042967],\n",
       "         [ 0.084106,  1.038407,  0.236938, -0.136968, -0.077328, -0.048223],\n",
       "         [ 0.081329,  0.992615,  0.228012, -0.061495, -0.390415, -0.032601],\n",
       "         ...,\n",
       "         [-0.936938,  0.46501 , -0.635976,  0.319458, -0.863067, -0.151261],\n",
       "         [-0.94113 ,  0.316814, -0.714352, -0.799177, -0.724849, -0.141858],\n",
       "         [-0.942344,  0.240762, -0.778274, -1.839198, -0.123219, -0.011225]]),\n",
       "  array([2, 2, 2, ..., 1, 1, 1])))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils_loader import test_idea_dataloader_ABC_to_BCA\n",
    "\n",
    "\n",
    "test_idea_dataloader_ABC_to_BCA({'seed': 25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
