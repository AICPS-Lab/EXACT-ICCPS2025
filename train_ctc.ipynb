{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from methods import Segmenter, TransformerModel, LSTM, CRNN, UNet,CCRNN, UNet2, PatchTST\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from methods.unetc import UNetc\n",
    "from methods.unetr import UNetrt\n",
    "from utilities import printc, seed\n",
    "from utils_loader import get_dataloaders, test_idea_dataloader_ABC_to_BCA, test_idea_dataloader_long_A_B_to_AB\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from utils_metrics import eval_dense_label_to_classification, mean_iou, visualize_softmax\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from utilities import sliding_windows\n",
    "import torch\n",
    "\n",
    "def load_data():\n",
    "    filename = './datasets/spar/spar_dataset'\n",
    "    # read through the folder that end with csv:\n",
    "    sw = sliding_windows(300, 150)\n",
    "    def process(files, sw, le: LabelEncoder):\n",
    "        nps = []\n",
    "        labels = []\n",
    "        for file in files:\n",
    "            df = pd.read_csv(os.path.join(filename, file))\n",
    "            nps.append(df.to_numpy()[:, 1:7])\n",
    "            labels.append([le.transform([file.split('_')[1]])[0]]*df.shape[0])\n",
    "        nps = np.concatenate(nps, axis=0)\n",
    "        labels = np.concatenate(labels, axis=0)\n",
    "        return sw(torch.tensor(nps).float(), torch.tensor(labels))\n",
    "    \n",
    "    classes = []\n",
    "    subjs = []\n",
    "    for root, dirs, files in os.walk(filename):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\") and 'R' in file:\n",
    "                label = file.split('_')[1]\n",
    "                subj = file.split('_')[0]\n",
    "                if label not in classes:\n",
    "                    classes.append(label)\n",
    "                if subj not in subjs:\n",
    "                    subjs.append(subj)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    \n",
    "    # read through the folder that end with csv:\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for each_subj in subjs:\n",
    "        collection = {class_name: [] for class_name in classes}\n",
    "        for root, dirs, files in os.walk(filename):\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\") and 'R' in file and each_subj == file.split('_')[0]:\n",
    "                    label = file.split('_')[1]\n",
    "                    collection[label].append(file)\n",
    "        leftover = []\n",
    "        for key in collection:\n",
    "            # sort the files\n",
    "            sorted_files = sorted(collection[key], key=lambda x: int(x.split('_')[3].split('.')[0]))\n",
    "            sample, lab = process(sorted_files, sw, le)\n",
    "            samples.append(sample)\n",
    "            labels.append(lab)\n",
    "    samples = torch.cat(samples, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    return samples, labels\n",
    "    \n",
    "\n",
    "def load_data1():\n",
    "    filename = './datasets/spar/spar_dataset'\n",
    "    seed = 0\n",
    "    # read through the folder that end with csv:\n",
    "    def combo_to_np(combo, le: LabelEncoder):\n",
    "        samples = []\n",
    "        labels = []\n",
    "        for each_combo in combo:\n",
    "            for each_file in each_combo:\n",
    "                df = pd.read_csv(os.path.join(filename, each_file))\n",
    "                samples.append(df.to_numpy()[:, 1:7])\n",
    "                transformed = le.transform([each_file.split('_')[1]])[0] + 1\n",
    "                labels.append([transformed] * df.shape[0])\n",
    "                # print('labels', labels)\n",
    "        # convert to np:\n",
    "        samples = np.concatenate(samples)\n",
    "        labels = np.concatenate(labels)\n",
    "        # print(samples.shape, labels.shape)\n",
    "        return samples, labels\n",
    "    \n",
    "    if True:\n",
    "        filename = './datasets/spar/spar_dataset'\n",
    "        seed = 0\n",
    "        # read through the folder that end with csv:\n",
    "        classes = []\n",
    "        subjs = []\n",
    "        for root, dirs, files in os.walk(filename):\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\") and 'R' in file:\n",
    "                    label = file.split('_')[1]\n",
    "                    subj = file.split('_')[0]\n",
    "                    if label not in classes:\n",
    "                        classes.append(label)\n",
    "                    if subj not in subjs:\n",
    "                        subjs.append(subj)\n",
    "                    # print(os.path.join(root, file))\n",
    "                    # df = pd.read_csv(os.path.join(root, file))\n",
    "\n",
    "        # generate train combo => ABC, ABD, ... # test combo => BCD (some combo that was not seem in train) based on the classes\n",
    "        train_combo = [('E1', 'E2', 'E3')]\n",
    "        test_combo = [('E3', 'E2', 'E1')]\n",
    "\n",
    "        assert all([each in classes for comb in train_combo for each in comb]), 'train combo not in classes'\n",
    "        assert all([each in classes for comb in test_combo for each in comb]), 'test combo not in classes'\n",
    "        train_classes = list(set([each for comb in train_combo for each in comb]))\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_classes)\n",
    "        random.seed(seed)\n",
    "        train_samples = []\n",
    "        test_samples = []\n",
    "        for each_subj in subjs:\n",
    "            collection = {class_name: [] for class_name in classes}\n",
    "            for root, dirs, files in os.walk(filename):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".csv\") and 'R' in file and each_subj == file.split('_')[0]:\n",
    "                        label = file.split('_')[1]\n",
    "                        collection[label].append(file)\n",
    "\n",
    "            lengths = [len(collection[class_name]) for class_name in classes]\n",
    "            minimum = min(lengths)\n",
    "            # 80% for train, 20% for test\n",
    "            train_length = int(minimum * 0.8)\n",
    "            test_length = minimum - train_length\n",
    "            # print(f'{each_subj} has {minimum} samples, {train_length} for train, {test_length} for test')\n",
    "            # generate train and test data\n",
    "            \n",
    "            # randomly extract one sample of label from the collection and remove that label from the list in the collection:\n",
    "            for _ in range(train_length):\n",
    "                for i in train_combo:\n",
    "                    cur_combo = []\n",
    "                    for j in i:\n",
    "                        selected_sample = random.choice(collection[j])\n",
    "                        collection[j].remove(selected_sample)\n",
    "                        cur_combo.append(selected_sample)\n",
    "                    train_samples.append(cur_combo)\n",
    "            for _ in range(test_length):\n",
    "                for i in test_combo:\n",
    "                    cur_combo = []\n",
    "                    for j in i:\n",
    "                        selected_sample = random.choice(collection[j])\n",
    "                        collection[j].remove(selected_sample)\n",
    "                        cur_combo.append(selected_sample)\n",
    "                    test_samples.append(cur_combo)\n",
    "        train_s = combo_to_np(train_samples, le)\n",
    "        test_s = combo_to_np(test_samples, le)\n",
    "    \n",
    "    sw = sliding_windows(300, 150)\n",
    "    \n",
    "    train_samples, train_labels = sw(torch.tensor(train_s[0]), torch.tensor(train_s[1]))\n",
    "    test_samples, test_labels = sw(torch.tensor(test_s[0]), torch.tensor(test_s[1]))\n",
    "    # Split the dataset into train, val and test:\n",
    "    train_samples, val_samples, train_labels, val_labels = train_test_split(train_samples, train_labels, test_size=0.2, random_state=42)\n",
    "    return train_samples, val_samples, test_samples, train_labels, val_labels, test_labels\n",
    "\n",
    "# samples, labels = load_data() \n",
    "train_samples, val_samples, test_samples, train_labels, val_labels, test_labels = load_data1()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset for ctc:\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = samples\n",
    "        self.labels = self._get_labels_ctc(labels)\n",
    "        self.sec_labels = labels\n",
    "    def _get_labels_ctc(self, labels):\n",
    "        # convert the labels to ctc format\n",
    "        # [1, 1, 1, 2, 2, 2, 3, 3, 3] -> [1, 2, 3], 3\n",
    "        lis = []\n",
    "        \n",
    "        # when the new label is different from the previous one, append the previous one to the list\n",
    "        for i in range(len(labels)):\n",
    "            cur_list = []\n",
    "            prev = labels[i, 0]\n",
    "            count = 1\n",
    "            for j in range(1, len(labels[i])):\n",
    "                if labels[i, j] == prev:\n",
    "                    if j == len(labels[i]) - 1:\n",
    "                        cur_list.append(prev)\n",
    "                else:\n",
    "                    cur_list.append(prev)\n",
    "                    prev = labels[i, j]\n",
    "                    count += 1\n",
    "            cur_list = torch.tensor(cur_list)\n",
    "            lis.append(cur_list)\n",
    "        return lis\n",
    "    @staticmethod\n",
    "    def custom_collate_fn(x):\n",
    "        batch = []\n",
    "        labels = []\n",
    "        lengths = []\n",
    "        for i in range(len(x)):\n",
    "            batch.append(x[i][0])\n",
    "            labels.extend(x[i][1])\n",
    "            lengths.append(len(x[i][1]))\n",
    "            # lengths.append()\n",
    "        batch = torch.stack(batch)\n",
    "        labels = torch.tensor(labels)\n",
    "        lengths = torch.tensor(lengths)\n",
    "        return batch, labels, lengths\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        # target, target_length\n",
    "        return self.samples[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0647,  0.9615,  0.0924,  0.1412, -0.4686,  0.1007],\n",
      "        [-0.0966,  1.0618, -0.0325,  1.4089, -0.4995, -0.0883],\n",
      "        [-0.0858,  1.1061, -0.0654,  2.7545, -0.4749, -0.0541],\n",
      "        ...,\n",
      "        [ 0.0744,  1.0504,  0.1003, -0.4283,  0.8970,  0.1164],\n",
      "        [ 0.1153,  1.0952,  0.0739, -0.4758,  0.8297,  0.1285],\n",
      "        [ 0.1320,  1.0930,  0.0518, -0.1923,  0.7045,  0.0943]],\n",
      "       dtype=torch.float64), tensor([3, 1, 2, 3], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_samples, train_labels)\n",
    "val_dataset = CustomDataset(val_samples, val_labels)\n",
    "test_dataset = CustomDataset(test_samples, test_labels)\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    print(train_dataset[i])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=CustomDataset.custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=CustomDataset.custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=CustomDataset.custom_collate_fn)\n",
    "\n",
    "# z = next(iter(train_loader))\n",
    "z = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm:\n",
    "\n",
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangh\\AppData\\Local\\Temp\\ipykernel_5828\\3474294761.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_count = torch.tensor(labels_count).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [10/19], Loss: 2.6600\n",
      "Epoch [2/50], Step [10/19], Loss: 1.6273\n",
      "Epoch [3/50], Step [10/19], Loss: 1.5889\n",
      "Epoch [4/50], Step [10/19], Loss: 1.5786\n",
      "Epoch [5/50], Step [10/19], Loss: 1.6004\n",
      "Epoch [6/50], Step [10/19], Loss: 1.5626\n",
      "Epoch [7/50], Step [10/19], Loss: 1.5880\n",
      "Epoch [8/50], Step [10/19], Loss: 1.5675\n",
      "Epoch [9/50], Step [10/19], Loss: 1.5863\n",
      "Epoch [10/50], Step [10/19], Loss: 1.5966\n",
      "Epoch [11/50], Step [10/19], Loss: 1.5691\n",
      "Epoch [12/50], Step [10/19], Loss: 1.5695\n",
      "Epoch [13/50], Step [10/19], Loss: 1.5824\n",
      "Epoch [14/50], Step [10/19], Loss: 1.5929\n",
      "Epoch [15/50], Step [10/19], Loss: 1.5602\n",
      "Epoch [16/50], Step [10/19], Loss: 1.5884\n",
      "Epoch [17/50], Step [10/19], Loss: 1.5584\n",
      "Epoch [18/50], Step [10/19], Loss: 1.6002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     16\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(outputs.shape, labels.shape, labels_count.shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wangh\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wangh\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\wangh\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wangh\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wangh\\anaconda3\\envs\\research\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM(6, 512, 4, 4).to(device)\n",
    "criterion = torch.nn.CTCLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(100):\n",
    "    for i, (images, labels, labels_count) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels_count = torch.tensor(labels_count).to(device)\n",
    "        # Forward pass\n",
    "        images = images.float()\n",
    "        outputs = model(images)\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "        # print(outputs.shape, labels.shape, labels_count.shape)\n",
    "        input_lengths = torch.full((images.shape[0],), images.shape[1], dtype=torch.long).to(device)\n",
    "        loss = criterion(outputs.transpose(0, 1), labels.cpu(),  input_lengths.cpu(), labels_count.cpu())\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{50}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangh\\AppData\\Local\\Temp\\ipykernel_5828\\2949538086.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_count = torch.tensor(labels_count).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([3, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
      "tensor([2, 1, 3], device='cuda:0', dtype=torch.int32)\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=torch.int32)\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[3, 2, 1, 2, 1, 3, 1, 3, 2, 1, 3, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 2, 1, 3, 2, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 1, 3, 2, 1, 3, 2, 2, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 1, 3, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def aggregate(output):\n",
    "    total = []\n",
    "    for i in range(len(output)):\n",
    "        prev = int(output[i][0])\n",
    "        for j in range(1, len(output[i])):\n",
    "            if output[i][j] != prev and output[i][j] != 0:\n",
    "                total.append(prev)\n",
    "                prev = int(output[i][j])\n",
    "        total.append(prev)\n",
    "    return total\n",
    "\n",
    "# test:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, labels_count in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels_count = torch.tensor(labels_count).to(device)\n",
    "        images = images.float()\n",
    "        outputs = model(images)\n",
    "        # print(outputs.shape)\n",
    "        # print(outputs)\n",
    "        outputs = F.softmax(outputs, dim=2)\n",
    "        input_lengths = torch.full((images.shape[0],), images.shape[1], dtype=torch.long)\n",
    "        loss = criterion(outputs.permute(1, 0, 2), labels.cpu(),  input_lengths.cpu(), labels_count.cpu())\n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        total += labels.size(0)\n",
    "        i = 1\n",
    "        print(predicted[i])\n",
    "        print(labels_count)\n",
    "        print(labels[labels_count[i-1]: labels_count[i-1]+labels_count[i]])\n",
    "        print(test_loader.dataset.sec_labels[i])\n",
    "        plt.plot(test_loader.dataset.sec_labels[i])\n",
    "        s = aggregate(predicted)\n",
    "        \n",
    "        print(s,)\n",
    "        print(labels.tolist())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
