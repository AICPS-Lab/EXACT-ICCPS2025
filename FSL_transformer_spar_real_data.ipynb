{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# #rename physiq filenames:\n",
    "# folder = \"datasets/physiq_copy/segment_sessions_one_repetition_data_E4/\"\n",
    "# filelabels = []\n",
    "# for filename in os.listdir(folder):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         filelist = filename.split(\"_\")\n",
    "#         if filelist[3] not in filelabels:\n",
    "#             filelabels.append(filelist[3])\n",
    "#         # filelist.pop(3) \n",
    "# # sort the list:\n",
    "# filelabels.sort()\n",
    "# for filename in os.listdir(folder):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         filelist = list(filename.split(\"_\"))\n",
    "#         print(filelist)\n",
    "#         filelist[1] = str(filelabels.index(filelist[3]))\n",
    "#         filelist.pop(3)\n",
    "#         filelist.pop(3)\n",
    "#         newname = \"_\".join(filelist)\n",
    "#         print(filelist, newname)\n",
    "#         os.rename(folder+filename, folder+newname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "# sw = sliding_windows(100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data( directory, window_size=75, step_size=32, pick_one=1, range=(0, 6)):\n",
    "    from utilities import sliding_windows\n",
    "    sw = sliding_windows(window_size, step_size)\n",
    "    label_maps = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            if filename.split(\"_\")[1] not in label_maps:\n",
    "                label_maps.append(filename.split(\"_\")[1])\n",
    "    print(len(label_maps))\n",
    "    assert pick_one < len(label_maps), \"pick_one is out of range\"\n",
    "    save_data = []\n",
    "    save_label = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            data = pd.read_csv(directory+filename)\n",
    "            data_np = data.to_numpy()[:, range[0]:range[1]]\n",
    "            if pick_one >= 0:\n",
    "                if filename.split(\"_\")[1] != label_maps[pick_one]:\n",
    "                    cls = 0\n",
    "                else:\n",
    "                    cls = 1\n",
    "            else:\n",
    "                cls = label_maps.index(filename.split(\"_\")[1])\n",
    "            label = np.array([cls] * data_np.shape[0])\n",
    "            data_windows, label_windows = sw.forward(torch.tensor(data_np), labels=torch.tensor(label))\n",
    "            save_data.append(data_windows)\n",
    "            save_label.append(label_windows)\n",
    "    save_data = torch.cat(save_data)\n",
    "    save_label = torch.cat(save_label)\n",
    "    return save_data, save_label\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom Dataset:\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            return self.transform(self.data[idx]), self.label[idx]\n",
    "        return self.data[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from utils_loader import MultiEpochsDataLoader\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import torch\n",
    "\n",
    "class StandardTransform(torch.nn.Module):\n",
    "    def __init__(self, scaler='standard'):\n",
    "        super(StandardTransform, self).__init__()\n",
    "        if scaler == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        else:\n",
    "            raise NotImplementedError('Only standard scaler is implemented')\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        data = self.scaler.transform(data)\n",
    "        return torch.tensor(data)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        n_samples, n_time_steps, n_features = data.shape\n",
    "        data_reshaped = data.reshape(-1, n_features)  # The shape becomes (n_samples * n_time_steps, n_features)\n",
    "        self.scaler.fit(data_reshaped)\n",
    "        print('Fitted with mean: {}, and std: {}'.format(self.scaler.mean_, np.sqrt(self.scaler.var_)))\n",
    "        return self\n",
    "    \n",
    "\n",
    "seed(73054772)\n",
    "directory = './raw_datasets/SPAR/'\n",
    "\n",
    "# create train, val, test dataset:\n",
    "segmented_samples, segmented_labels = generate_data(directory, window_size=100, step_size=50, pick_one=-1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(segmented_samples, segmented_labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "d, l = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available.\n"
     ]
    }
   ],
   "source": [
    "# model:\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from utilities import *\n",
    "from torch.nn.modules.transformer import TransformerEncoder, TransformerEncoderLayer\n",
    "num_epochs = 300\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=6, hidden_size=1024, num_layers=2, output_size=18):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "import torch.nn.functional as F\n",
    "import math \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "from torch.nn.modules.transformer import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "\n",
    "class SimpleSegmenterMaskTransformer(nn.Module):\n",
    "    def __init__(self, in_channels=6, num_layers=2, num_heads=4, embed_dims=256, **kwargs):\n",
    "        super(SimpleSegmenterMaskTransformer, self).__init__(**kwargs)\n",
    "\n",
    "        # Fixed parameters for simplicity\n",
    "        mlp_ratio = 4\n",
    "        # norm_cfg = dict(type='LN')\n",
    "        # act_cfg = dict(type='GELU')\n",
    "        self.init_std = 0.02\n",
    "        self.num_classes = 7\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            layer = nn.TransformerEncoderLayer(\n",
    "                d_model=embed_dims,\n",
    "                nhead=num_heads,\n",
    "                dim_feedforward=mlp_ratio * embed_dims,\n",
    "                dropout=0.5,\n",
    "                activation=F.gelu,\n",
    "                layer_norm_eps=1e-05,\n",
    "                batch_first=True,\n",
    "                norm_first=False,\n",
    "                bias=True\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.dec_proj = nn.Linear(in_channels, embed_dims)\n",
    "        self.cls_emb = nn.Parameter(torch.randn(1, self.num_classes, embed_dims))\n",
    "        self.patch_proj = nn.Linear(embed_dims, embed_dims, bias=False)\n",
    "        self.classes_proj = nn.Linear(embed_dims, embed_dims, bias=False)\n",
    "        self.decoder_norm = nn.LayerNorm(embed_dims)\n",
    "        self.mask_norm = nn.LayerNorm(self.num_classes)\n",
    "        self.init_weights()\n",
    "    def init_weights(self):\n",
    "        nn.init.trunc_normal_(self.cls_emb, std=self.init_std)\n",
    "        nn.init.trunc_normal_(self.patch_proj.weight, std=self.init_std)\n",
    "        nn.init.trunc_normal_(self.classes_proj.weight, std=self.init_std)\n",
    "        # Initialize weights for Transformer layers\n",
    "        for layer in self.layers:\n",
    "            for param in layer.parameters():\n",
    "                if param.dim() > 1:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.permute(0, 2, 1) # b h c\n",
    "        b, c, h = x.shape\n",
    "        x = x.view(b, c, -1).permute(0, 2, 1)\n",
    "\n",
    "        x = self.dec_proj(x)\n",
    "        cls_emb = self.cls_emb.expand(x.size(0), -1, -1)\n",
    "        x = torch.cat((x, cls_emb), 1)\n",
    "        for layer in self.layers: \n",
    "            x = layer(x)\n",
    "        x = self.decoder_norm(x)\n",
    "\n",
    "        patches = self.patch_proj(x[:, :-self.num_classes]) # shape 128, 75, 64\n",
    "        cls_seg_feat = self.classes_proj(x[:, -self.num_classes:])\n",
    "        # cls_seg_feat = nn.functional.dropout(cls_seg_feat, p=0.5, training=self.training)\n",
    "        patches = F.normalize(patches, dim=2, p=2)\n",
    "        cls_seg_feat = F.normalize(cls_seg_feat, dim=2, p=2)\n",
    "        # print(patches.shape)\n",
    "        masks = patches @ cls_seg_feat.transpose(1, 2)\n",
    "        masks = self.mask_norm(masks).contiguous().view(b, h, -1)\n",
    "\n",
    "        return masks\n",
    "\n",
    "    def forward_pred(self, inputs):\n",
    "        masks = self.forward(inputs)\n",
    "        masks = masks.permute(0, 2, 1)\n",
    "        probabilities = F.softmax(masks, dim=1)\n",
    "        pred = torch.argmax(probabilities, dim=1)\n",
    "        return pred\n",
    "\n",
    "    \n",
    "# class TransformerModel(nn.Module):\n",
    "#     \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
    "\n",
    "#     def __init__(self, ntoken=6, ninp=64, nhead=1, nhid=256, nlayers=6, dropout=0.1, activation='relu'):\n",
    "#         super(TransformerModel, self).__init__()\n",
    "#         self.input_emb = nn.Linear(ntoken, ninp)\n",
    "#         self.ninp = ninp\n",
    "#         self.relu = nn.ReLU()\n",
    "#         encoder_layer = nn.TransformerEncoderLayer(d_model=ninp, nhead=nhead, dim_feedforward=nhid, dropout=dropout, activation=activation, batch_first=True)\n",
    "#         encoder_norm = nn.LayerNorm(ninp)   \n",
    "#         self.transformer_encoder = TransformerEncoder(encoder_layer, nlayers, norm=encoder_norm)\n",
    "#         self.decoder = nn.Linear(ninp, 2)\n",
    "#         # max layer:\n",
    "#         # self.max = nn.MaxPool1d(100)\n",
    "#         self.psi = nn.Linear(100, 100)\n",
    "\n",
    "#     def forward(self, src):\n",
    "#         src = self.input_emb(src)\n",
    "#         src = self.relu(src)\n",
    "#         output = self.transformer_encoder(src)\n",
    "        \n",
    "#         # max layer:\n",
    "#         # output = output.transpose(0, 1)\n",
    "#         # output = self.max(output)\n",
    "#         # output = output.transpose(1, 2)\n",
    "#         output = self.decoder(output)\n",
    "#         # print(output.shape)\n",
    "#         # output = output.squeeze(-1)\n",
    "#         # output = self.psi(output)\n",
    "        \n",
    "#         return nn.functional.sigmoid(output)\n",
    "    \n",
    "#         # return F.sigmoid(output).squeeze(-1) # return F.log_softmax(output, dim=-1)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou_time_series(pred, gt, num_classes=7):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Intersection over Union (mIoU) for time series data.\n",
    "    \n",
    "    Parameters:\n",
    "        pred (torch.Tensor): Predictions, assumed to be one-hot encoded.\n",
    "        gt (torch.Tensor): Ground truth labels, assumed to be one-hot encoded.\n",
    "        num_classes (int): Number of classes in the segmentation task.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean IoU for the batch.\n",
    "    \"\"\"\n",
    "    # Initialize variables to store IoU for each class\n",
    "    iou_list = []\n",
    "\n",
    "    # Loop through each class\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        gt_inds = gt == cls\n",
    "\n",
    "        # Calculate Intersection and Union\n",
    "        # print(pred_inds.shape, gt_inds.shape)\n",
    "        intersection = torch.sum(pred_inds & gt_inds, dim=1).float()\n",
    "        union = torch.sum(pred_inds | gt_inds, dim=1).float()\n",
    "\n",
    "        # Calculate IoU. Avoid division by zero by adding a small epsilon.\n",
    "        iou = intersection / (union + 1e-8)\n",
    "\n",
    "        # Append the mean IoU for this class\n",
    "        iou_list.append(torch.mean(iou))\n",
    "\n",
    "    # Calculate the mean IoU across all classes\n",
    "    mean_iou = torch.mean(torch.stack(iou_list))\n",
    "\n",
    "    return mean_iou.item()\n",
    "\n",
    "\n",
    "def mean_iou(preds, labels, num_classes):\n",
    "    # Flatten the predictions and labels, this comes from the argmax of the one-hot vectors\n",
    "    preds = preds.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            confusion_matrix[i, j] = torch.sum((preds == i) & (labels == j))\n",
    "\n",
    "    # Calculate IoU for each class\n",
    "    ious = []\n",
    "    for i in range(num_classes):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = confusion_matrix[i, :].sum() - true_positive\n",
    "        false_negative = confusion_matrix[:, i].sum() - true_positive\n",
    "\n",
    "        # Avoid division by zero\n",
    "        union = true_positive + false_positive + false_negative\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # No predictions and no labels for this class\n",
    "        else:\n",
    "            ious.append(true_positive.float() / union.float())\n",
    "\n",
    "    # Calculate mean IoU\n",
    "    ious = torch.tensor(ious)\n",
    "    mean_iou = torch.nanmean(ious)  # Mean over all classes, ignoring NaNs\n",
    "    return mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     64\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m loss, tra_ce, tra_pen \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mcustom_loss\u001b[0;34m(logits, targets, penalty_weight)\u001b[0m\n\u001b[1;32m     31\u001b[0m penalty \u001b[38;5;241m=\u001b[39m c_loss(logits)\n\u001b[1;32m     32\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m ce_loss \u001b[38;5;66;03m#penalty * penalty_weight\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss, \u001b[43mce_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, penalty\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create an instance of the CNN model\n",
    "from livelossplot import PlotLosses\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "def c_loss(logits):\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    one_hot_predictions = torch.argmax(probabilities, dim=1)\n",
    "    product_prob = torch.prod(probabilities, dim=1)\n",
    "    changes = torch.abs(one_hot_predictions[:, 1:]*product_prob[:, 1:] - one_hot_predictions[:, :-1]*product_prob[:, :-1])\n",
    "    penalty = changes.sum(dim=1).float().mean()\n",
    "    return penalty + 1e-4\n",
    "def custom_loss(logits, targets, penalty_weight=0.1):\n",
    "    \"\"\"\n",
    "    Custom loss function that penalizes frequent changes in the prediction sequence.\n",
    "    \n",
    "    Args:\n",
    "    - logits: Tensor of shape [N, C, L], where N is batch size, C is number of classes, and L is sequence length.\n",
    "    - targets: Tensor of shape [N, L] containing class indices for each element in the sequence.\n",
    "    - penalty_weight: Weight of the penalty term.\n",
    "\n",
    "    Returns:\n",
    "    - Total loss with the penalty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Standard cross-entropy loss\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    ce_loss = F.cross_entropy(probabilities, targets)\n",
    "\n",
    "    penalty = c_loss(logits)\n",
    "    total_loss = ce_loss #penalty * penalty_weight\n",
    "\n",
    "    return total_loss, ce_loss.item(), penalty.item()\n",
    "\n",
    "def plotASample(data, label):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)  # Add a new subplot to the figure\n",
    "    ax.plot(data, label='Data')  # Plot the data\n",
    "    ax.plot(label, label='Label')  # Plot the label\n",
    "    ax.legend()  # Add a legend\n",
    "    fig.canvas.draw()  # Redraw the figure\n",
    "    plt.plot()\n",
    "\n",
    "\n",
    "model = SimpleSegmenterMaskTransformer().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion =custom_loss #nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.00)\n",
    "liveloss = PlotLosses()\n",
    "\n",
    "# Iterate over the training data\n",
    "logs = {}\n",
    "# change the plt size:\n",
    "best_loss = math.inf\n",
    "counter_i = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        images = images.float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.permute(0, 2, 1)\n",
    "        loss, tra_ce, tra_pen = criterion(outputs, labels.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # train loss and accuracy check:\n",
    "        if counter_i % 1000 == 0 and counter_i != 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # total = labels.size(0)\n",
    "            # correct = (predicted == labels).sum().item()\n",
    "            # print('Accuracy: {:.2f}%'.format(correct / total * 100))\n",
    "            logs['loss'] = loss.item()\n",
    "            logs['ce'] = tra_ce\n",
    "            logs['pen'] = tra_pen\n",
    "            # logs['accuracy'] = correct / total * 100\n",
    "    \n",
    "            # validation loss and accuracy check:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in val_loader:\n",
    "                images = images.float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                outputs = outputs.permute(0, 2, 1) #view(images.shape[0], 2, -1)\n",
    "                loss, val_ce, val_pen = criterion(outputs, labels.long())\n",
    "            logs['val_loss'] = loss.item()\n",
    "            logs['val_ce'] = val_ce\n",
    "            logs['val_pen'] = val_pen\n",
    "            logs['miou'] = mean_iou(model.forward_pred(images), labels.long())\n",
    "            if best_loss > loss.item():\n",
    "                best_loss = loss.item()\n",
    "                torch.save(model.state_dict(), './saved_model/best_transformer_spar.pth')\n",
    "            pred = torch.argmax(torch.softmax(outputs[0], dim=0), dim=0).detach().cpu().numpy()\n",
    "            plotASample(images[0].detach().cpu().numpy(), pred)\n",
    "            liveloss.update(logs)\n",
    "            liveloss.send()\n",
    "            # logs['val_accuracy'] = correct / total * 100\n",
    "        counter_i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mIoU coefficient: tensor(0.9181)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "\n",
    "\n",
    "model = SimpleSegmenterMaskTransformer().to(device)\n",
    "model.load_state_dict(torch.load('./saved_model/best_transformer_spar.pth', map_location=device))\n",
    "\n",
    "model.eval()\n",
    "miou, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        data = data.float().to(device)\n",
    "        label = label.squeeze().long().to(device)\n",
    "        output = model.forward_pred(data)\n",
    "        # print(output.shape, label.shape)\n",
    "        # print(output[0], label[0])\n",
    "        miou += mean_iou(output, label, 7)\n",
    "        total += 1\n",
    "        \n",
    "        # print('output', output)])\n",
    "        # plt.plot(data[0].view(-1, 6).cpu().numpy(), color='black')\n",
    "        # plt.plot(output[0].view(-1).detach().squeeze().cpu().numpy(), color='green')\n",
    "        # plt.plot(label[0].view(-1).cpu().numpy(), color='red')\n",
    "        # plt.show()\n",
    "        # # wait for 1 sec:\n",
    "        # time.sleep(1)\n",
    "        # erase the output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "print('mIoU coefficient:', miou / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m combo \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m num_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of random combinations to generate\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mlist_files\u001b[49m(directory)\n\u001b[1;32m      6\u001b[0m groups \u001b[38;5;241m=\u001b[39m group_files(files)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# randomly pick one group from the dic:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_files' is not defined"
     ]
    }
   ],
   "source": [
    "# few show learning on a new dataset:\n",
    "directory = './datasets/physiq_copy/segment_sessions_one_repetition_data_E2'\n",
    "combo = ['1', '2']\n",
    "num_results = 1  # Number of random combinations to generate\n",
    "files = list_files(directory)\n",
    "groups = group_files(files)\n",
    "# randomly pick one group from the dic:\n",
    "key = random.choice(list(groups.keys()))\n",
    "group = groups[key]\n",
    "combinations,labels = generate_combinations(group, combo, num_results)\n",
    "# print(combinations)\n",
    "\n",
    "\n",
    "segmented_samples = []\n",
    "segmented_labels = []\n",
    "for i, (order, label) in enumerate(zip(combinations, labels)):\n",
    "    print('length', len(order), order, label)\n",
    "    concatenated_np, concat_label = concatenate_data(directory, group, order, label=label)\n",
    "    \n",
    "    conc_data = torch.tensor(concatenated_np)\n",
    "    conc_label = torch.tensor(concat_label)\n",
    "    \n",
    "    segmented_sample, segmneted_label  = sw.forward(conc_data, conc_label)\n",
    "    segmented_samples.append(segmented_sample)\n",
    "    segmented_labels.append(segmneted_label)\n",
    "\n",
    "segmented_samples = torch.cat(segmented_samples)\n",
    "segmented_labels = torch.cat(segmented_labels)\n",
    "support_Size = len(segmented_labels)\n",
    "# change it to be dataset\n",
    "dl = DataLoader(CustomDataset(segmented_samples, segmented_labels), batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 7 ['1', '1', '0', '1', '2', '1', '1'] [0, 0, 0, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# few show learning on a new dataset:\n",
    "directory = './datasets/physiq_copy/segment_sessions_one_repetition_data_E2'\n",
    "combo = ['1', '2']\n",
    "num_results = 1  # Number of random combinations to generate\n",
    "files = list_files(directory)\n",
    "groups = group_files(files)\n",
    "# randomly pick one group from the dic:\n",
    "key = random.choice(list(groups.keys()))\n",
    "group = groups[key]\n",
    "combinations,labels = generate_combinations(group, combo, num_results)\n",
    "# print(combinations)\n",
    "\n",
    "\n",
    "segmented_samples = []\n",
    "segmented_labels = []\n",
    "for i, (order, label) in enumerate(zip(combinations, labels)):\n",
    "    print('length', len(order), order, label)\n",
    "    concatenated_np, concat_label = concatenate_data(directory, group, order, label=label)\n",
    "    \n",
    "    conc_data = torch.tensor(concatenated_np)\n",
    "    conc_label = torch.tensor(concat_label)\n",
    "    \n",
    "    segmented_sample, segmneted_label  = sw.forward(conc_data, conc_label)\n",
    "    segmented_samples.append(segmented_sample)\n",
    "    segmented_labels.append(segmneted_label)\n",
    "\n",
    "segmented_samples = torch.cat(segmented_samples)\n",
    "segmented_labels = torch.cat(segmented_labels)\n",
    "\n",
    "# change it to be dataset\n",
    "test_dl = DataLoader(CustomDataset(segmented_samples, segmented_labels), batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_to_prototypes(A, B) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute prediction logits from their cosine distance to support set prototypes.\n",
    "    Args:\n",
    "        samples: features of the items to classify of shape (n_samples, feature_dimension)\n",
    "    Returns:\n",
    "        prediction logits of shape (n_samples, n_classes)\n",
    "    \"\"\"\n",
    "    return torch.nn.functional.normalize(A, p=2, dim=1) @ torch.nn.functional.normalize(B, p=2, dim=1).T\n",
    "\n",
    "def get_logits(features: torch.tensor, prototype, temperature=0.1) -> torch.tensor:\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between self.prototype and given features\n",
    "    inputs:\n",
    "        features : shape [n_tasks, shot, c, h]\n",
    "\n",
    "    returns :\n",
    "        logits : shape [n_tasks, shot, h]\n",
    "    \"\"\"\n",
    "\n",
    "    # Put prototypes and features in the right shape for multiplication\n",
    "    features = features.permute((0, 1, 3, 2))  # [n_task, shot, h, c]\n",
    "    print('features should n=N, shot=1, h=100, c=64', features.shape)\n",
    "    prototype = prototype.unsqueeze(1).unsqueeze(2)  # [n_tasks, 1, 1, c]\n",
    "    print('prototype = [n_tasks, 1, 1, c]', prototype.shape)\n",
    "    print(prototype.shape)\n",
    "    # Compute cosine similarity\n",
    "    cossim = features.matmul(prototype.unsqueeze(3)).squeeze(3) # [n_task, shot, h=100, w]\n",
    "    cossim /= ((prototype.unsqueeze(3).norm(dim=4) * \\\n",
    "                features.norm(dim=4)) + 1e-10)  # [n_tasks, shot, h, w]\n",
    "\n",
    "    return temperature * cossim\n",
    "    \n",
    "def init_prototypes(features_s, features_q, support_labels, n_task=2, c=1):\n",
    "    \"\"\"\n",
    "        inputs:\n",
    "            n_task = N, shot = 1, c is the hidden feature (channel) = 64, h = 100\n",
    "            features_s : shape [n_task, shot, c, h]\n",
    "            features_q : shape [n_task, 1, c, h]\n",
    "            gt_s : shape [n_task, shot, H]\n",
    "            gt_q : shape [n_task, 1, H]\n",
    "\n",
    "        returns :\n",
    "            prototypes : shape [n_task, c]\n",
    "            bias : shape [n_task]\n",
    "    \"\"\"\n",
    "    # Computing prototypes\n",
    "    fg_mask = (support_labels == 1)\n",
    "    fg_mask = fg_mask.unsqueeze(1) # [n_task, shot=1, 100]\n",
    "    print(\"fg_mask\", fg_mask.shape)\n",
    "    print(\"features_s\", features_s.shape)\n",
    "    fg_prototype = (features_s * fg_mask).sum(dim=1)\n",
    "    fg_prototype /= (fg_mask.sum(dim=1) + 1e-10)  # [n_task, c]\n",
    "\n",
    "    prototype = fg_prototype\n",
    "    print('features_q, [n_tasks, 1, c, h]',features_q.shape)\n",
    "    features_q = features_q.unsqueeze(1)  # [n_tasks, 1, c, h]\n",
    "    logits_q = get_logits(features_q, prototype)  # [n_tasks, shot, h]\n",
    "    bias = logits_q.mean(dim=(1, 2))\n",
    "\n",
    "    assert prototype.size() == (n_task, c), prototype.size()\n",
    "    assert torch.isnan(prototype).sum() == 0, prototype\n",
    "    return \n",
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict query labels using labeled support images.\n",
    "        \"\"\"\n",
    "        # Extract the features of support and query images\n",
    "        z_support = self.backbone.forward(support_images)\n",
    "        z_query = self.backbone.forward(query_images)\n",
    "        z_support = z_support.permute(0, 2, 1 )\n",
    "        z_query = z_query.permute(0, 2, 1 )\n",
    "        print(z_support.shape, z_query.shape, support_labels.shape)\n",
    "        init_prototypes(z_support, z_query, support_labels)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.decoder = nn.Identity()\n",
    "prototype_model = PrototypicalNetworks(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 75, 6])\n",
      "torch.Size([5, 75, 6])\n",
      "torch.Size([5, 64, 75]) torch.Size([5, 64, 75]) torch.Size([5, 75])\n",
      "fg_mask torch.Size([5, 1, 75])\n",
      "features_s torch.Size([5, 64, 75])\n",
      "features_q, [n_tasks, 1, c, h] torch.Size([5, 64, 75])\n",
      "features should n=N, shot=1, h=100, c=64 torch.Size([5, 1, 75, 64])\n",
      "prototype = [n_tasks, 1, 1, c] torch.Size([5, 1, 1, 75])\n",
      "torch.Size([5, 1, 1, 75])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [25, 64] but got: [25, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sample[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_sample[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mprototype_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# z.shape\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[226], line 85\u001b[0m, in \u001b[0;36mPrototypicalNetworks.forward\u001b[0;34m(self, support_images, support_labels, query_images)\u001b[0m\n\u001b[1;32m     83\u001b[0m z_query \u001b[38;5;241m=\u001b[39m z_query\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(z_support\u001b[38;5;241m.\u001b[39mshape, z_query\u001b[38;5;241m.\u001b[39mshape, support_labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 85\u001b[0m \u001b[43minit_prototypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_support\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[226], line 59\u001b[0m, in \u001b[0;36minit_prototypes\u001b[0;34m(features_s, features_q, support_labels, n_task, c)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_q, [n_tasks, 1, c, h]\u001b[39m\u001b[38;5;124m'\u001b[39m,features_q\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     58\u001b[0m features_q \u001b[38;5;241m=\u001b[39m features_q\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [n_tasks, 1, c, h]\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m logits_q \u001b[38;5;241m=\u001b[39m \u001b[43mget_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprototype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n_tasks, shot, h]\u001b[39;00m\n\u001b[1;32m     60\u001b[0m bias \u001b[38;5;241m=\u001b[39m logits_q\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m prototype\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m (n_task, c), prototype\u001b[38;5;241m.\u001b[39msize()\n",
      "Cell \u001b[0;32mIn[226], line 29\u001b[0m, in \u001b[0;36mget_logits\u001b[0;34m(features, prototype, temperature)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(prototype\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m cossim \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprototype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;66;03m# [n_task, shot, h=100, w]\u001b[39;00m\n\u001b[1;32m     30\u001b[0m cossim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m ((prototype\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m     31\u001b[0m             features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)  \u001b[38;5;66;03m# [n_tasks, shot, h, w]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m temperature \u001b[38;5;241m*\u001b[39m cossim\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [25, 64] but got: [25, 1]."
     ]
    }
   ],
   "source": [
    "sample = next(iter(dl))\n",
    "test_sample = next(iter(test_dl))\n",
    "print(sample[0].shape)\n",
    "print(test_sample[0].shape)\n",
    "z = prototype_model.forward(sample[0].float().to(device), sample[1].float().to(device), test_sample[0].float().to(device))\n",
    "# z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
