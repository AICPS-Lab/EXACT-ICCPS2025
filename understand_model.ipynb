{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from methods.unet import UNet_encoder\n",
    "import torch\n",
    "from utils_loader import test_idea_dataloader_e2\n",
    "config = {\n",
    "    'batch_size': 128,\n",
    "    'epochs':200,\n",
    "    'fsl': False,\n",
    "    'model': 'unet',\n",
    "    'seed': 73054772,\n",
    "    'dataset': 'physiq'\n",
    "}\n",
    "train_loader, val_loader, test_loader = test_idea_dataloader_e2(config)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = UNet_encoder(in_channels=6, out_channels=5, cnn_embed_dims=[64, 128, 356]).float().to(device)\n",
    "model.load_state_dict(torch.load('saved_model/opportunity_unet_test_EXP2_B.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 6])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tensor target dimension torch.Size([1]) is not valid. torch.Size([5])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m label_1 \u001b[38;5;241m=\u001b[39m labels[torch\u001b[38;5;241m.\u001b[39mwhere(labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_0\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 11\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_gc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# upsampled_attr = LayerAttribution.interpolate(attr, (32, 32))\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.9/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.9/site-packages/captum/attr/_core/layer/grad_cam.py:195\u001b[0m, in \u001b[0;36mLayerGradCam.attribute\u001b[0;34m(self, inputs, target, additional_forward_args, attribute_to_layer_input, relu_attributions, attr_dim_summation)\u001b[0m\n\u001b[1;32m    190\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(\n\u001b[1;32m    191\u001b[0m     additional_forward_args\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Returns gradient of output with respect to\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# hidden layer and hidden layer evaluated at each input.\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m layer_gradients, layer_evals \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_layer_gradients_and_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattribute_to_layer_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribute_to_layer_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m summed_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    206\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m    207\u001b[0m         layer_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer_grad \u001b[38;5;129;01min\u001b[39;00m layer_gradients\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr_dim_summation:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.9/site-packages/captum/_utils/gradient.py:592\u001b[0m, in \u001b[0;36mcompute_layer_gradients_and_eval\u001b[0;34m(forward_fn, layer, inputs, target_ind, additional_forward_args, gradient_neuron_selector, device_ids, attribute_to_layer_input, output_fn)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to a given layer as well\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03mas the output evaluation of the layer for an arbitrary forward function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m        Target layer output for given input.\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;66;03m# saved_layer is a dictionary mapping device to a tuple of\u001b[39;00m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# layer evaluations on that device.\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m     saved_layer, output \u001b[38;5;241m=\u001b[39m \u001b[43m_forward_layer_distributed_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribute_to_layer_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribute_to_layer_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_hook_with_return\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_layer_grads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    607\u001b[0m     device_ids \u001b[38;5;241m=\u001b[39m _extract_device_ids(forward_fn, saved_layer, device_ids)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.9/site-packages/captum/_utils/gradient.py:294\u001b[0m, in \u001b[0;36m_forward_layer_distributed_eval\u001b[0;34m(forward_fn, inputs, layer, target_ind, additional_forward_args, attribute_to_layer_input, forward_hook_with_return, require_layer_grads)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m             all_hooks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    292\u001b[0m                 single_layer\u001b[38;5;241m.\u001b[39mregister_forward_hook(hook_wrapper(single_layer))\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m all_hooks:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.9/site-packages/captum/_utils/common.py:536\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m    531\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func(\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39madditional_forward_args)\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inputs\n\u001b[1;32m    535\u001b[0m )\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.9/site-packages/captum/_utils/common.py:592\u001b[0m, in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mgather(output, \u001b[38;5;241m1\u001b[39m, target\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(output), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor target dimension \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not valid. \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    594\u001b[0m             \u001b[38;5;241m%\u001b[39m (target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    595\u001b[0m         )\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m num_examples, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget list length does not match output!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor target dimension torch.Size([1]) is not valid. torch.Size([5])"
     ]
    }
   ],
   "source": [
    "from captum.attr import LayerGradCam, LayerAttribution\n",
    "# print(model.backbone[-2].conv2)\n",
    "layer_gc = LayerGradCam(model, model.backbone[-2].conv2)\n",
    "# get one sample from 0 and 1 label:\n",
    "inputs, labels = next(iter(test_loader))\n",
    "input_0 = inputs[torch.where(labels == 0)[0]][0].unsqueeze(0).float()\n",
    "input_1 = inputs[torch.where(labels == 1)[0]][0].unsqueeze(0).float()\n",
    "label_0 = labels[torch.where(labels == 0)[0]][0].unsqueeze(0).float()\n",
    "label_1 = labels[torch.where(labels == 1)[0]][0].unsqueeze(0).float()\n",
    "print(input_0.shape)\n",
    "attr = layer_gc.attribute(input_0, label_0)\n",
    "\n",
    "# upsampled_attr = LayerAttribution.interpolate(attr, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
